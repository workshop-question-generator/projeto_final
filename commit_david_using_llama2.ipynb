{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eRjysQA98n3"
      },
      "outputs": [],
      "source": [
        "!pip install sense2vec sentence_transformers textwrap3  flashtext strsimpy\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install langchain\n",
        "!pip install openai==1.3.8\n",
        "!pip install pypdf==3.17.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_RdgU5N_aIZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "HF_KEY = userdata.get('HF_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHOroe2c98n5"
      },
      "outputs": [],
      "source": [
        "#import all the neccessary libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "from sense2vec import Sense2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from textwrap3 import wrap\n",
        "import random\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pke\n",
        "import traceback\n",
        "from flashtext import KeywordProcessor\n",
        "from collections import OrderedDict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('omw-1.4')\n",
        "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
        "import pickle\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVa4J8LMisDU"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffXXmODfFHQk"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "from langchain import HuggingFaceHub, LLMChain\n",
        "\n",
        "summary_model = HuggingFaceHub(repo_id=\"t5-base\",\n",
        "                               task=\"summarization\",\n",
        "                               model_kwargs={\n",
        "                               \"early_stopping\":True,\n",
        "                               \"num_beams\":3,\n",
        "                               \"num_return_sequences\":1,\n",
        "                               \"no_repeat_ngram_size\":2,\n",
        "                               \"min_length\": 600,\n",
        "                               \"max_length\":2000},\n",
        "                               huggingfacehub_api_token=HF_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WvyZcxJ-Ldd"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "summary_template = ChatPromptTemplate.from_template(template=\"Summarize: {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwJ_Q7xzAPYx"
      },
      "outputs": [],
      "source": [
        "question_model = HuggingFaceHub(repo_id=\"ramsrigouthamg/t5_squad_v1\",\n",
        "                               task=\"text2text-generation\",\n",
        "                               model_kwargs={\n",
        "                               \"early_stopping\":True,\n",
        "                               \"num_beams\":5,\n",
        "                               \"num_return_sequences\":1,\n",
        "                               \"no_repeat_ngram_size\":2,\n",
        "                               \"max_length\": 72},\n",
        "                               huggingfacehub_api_token=HF_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSun0MKMAPJ_"
      },
      "outputs": [],
      "source": [
        "question_template = ChatPromptTemplate.from_template(template=\"context: {context} answer: {keyword}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQDZvqjooRpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_questions(summarized_text):\n",
        "  context = summarized_text\n",
        "  keywords = get_nouns_multipartite(context)\n",
        "\n",
        "  print(summarized_text)\n",
        "\n",
        "  questions = []\n",
        "  for keyword in keywords:\n",
        "    prompt=\"context: {context} answer: {keyword}\".format(context=context, keyword=keyword)\n",
        "    question = question_model(prompt)\n",
        "\n",
        "    distractors = get_distractors_wordnet(keyword)\n",
        "\n",
        "\n",
        "    # Confere se h√° distratores o suficiente\n",
        "    if(len(distractors) < 4):\n",
        "      comp = 4 - len(distractors)\n",
        "      try:\n",
        "        keywords_distractors = np.random.choice(keywords, size=comp, replace=False)\n",
        "      except:\n",
        "        keywords_distractors = np.random.choice(keywords, size=comp)\n",
        "      distractors.extend(keywords_distractors)\n",
        "\n",
        "    random_integer = random.randint(0, 3)\n",
        "    alpha_list = ['(a)','(b)','(c)','(d)']\n",
        "    for d, distractor in enumerate(distractors[:4]):\n",
        "        if d == random_integer:\n",
        "           question = question + alpha_list[d] + keyword + \"\\n\"\n",
        "        else:\n",
        "           question = question + alpha_list[d] + distractor + \"\\n\"\n",
        "\n",
        "    question = question + \"Correct answer is : \" + alpha_list[random_integer] + \"\\n\\n\"\n",
        "\n",
        "    questions.append(question)\n",
        "\n",
        "  return questions\n",
        "\n",
        "\n",
        "def get_nouns_multipartite(content):\n",
        "    out=[]\n",
        "    try:\n",
        "        extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor.load_document(input=content,language='en')\n",
        "        pos = {'PROPN', 'NOUN', 'ADJ', 'VERB', 'ADP', 'ADV', 'DET', 'CONJ', 'NUM', 'PRON', 'X'}\n",
        "\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        extractor.candidate_selection( pos=pos)\n",
        "        extractor.candidate_weighting(alpha=1.1,\n",
        "                                      threshold=0.75,\n",
        "                                      method='average')\n",
        "        keyphrases = extractor.get_n_best(n=15)\n",
        "\n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_distractors_wordnet(word):\n",
        "    distractors=[]\n",
        "    try:\n",
        "      syn = wn.synsets(word,'n')[0]\n",
        "\n",
        "      word= word.lower()\n",
        "      orig_word = word\n",
        "      if len(word.split())>0:\n",
        "          word = word.replace(\" \",\"_\")\n",
        "      hypernym = syn.hypernyms()\n",
        "      if len(hypernym) == 0:\n",
        "          return distractors\n",
        "      for item in hypernym[0].hyponyms():\n",
        "          name = item.lemmas()[0].name()\n",
        "          if name == orig_word:\n",
        "              continue\n",
        "          name = name.replace(\"_\",\" \")\n",
        "          name = \" \".join(w.capitalize() for w in name.split())\n",
        "          if name is not None and name not in distractors:\n",
        "              distractors.append(name)\n",
        "    except:\n",
        "      print (\"Wordnet distractors not found\")\n",
        "    return distractors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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"
      ],
      "metadata": {
        "id": "uo5NrOj1Khfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "I9LOX6hYO0Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", torch_dtype =\"auto\", load_in_4bit=True)"
      ],
      "metadata": {
        "id": "1cQ5DBjrICXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", torch_dtype =\"auto\")"
      ],
      "metadata": {
        "id": "6OuOQsl9SBMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "pipeline = transformers.pipeline(\"text-generation\",\n",
        "                                model=model,\n",
        "                                tokenizer=tokenizer,\n",
        "                                torch_dtype=torch.float16,\n",
        "                                device_map=\"auto\")"
      ],
      "metadata": {
        "id": "f_VYj2nySMrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_template = \"<s>[INST] <<SYS>>\\n{your_system_message}\\n<</SYS>>\\n\\n{user_message_1} [/INST]\"\n",
        "your_system_message = \"I need you to take this text, which is the statement of a question, and amplify it. That means you should expand the statement, making it longer while preserving the original meaning and intent of the question. The goal is to create an extended version of the question's statement that, when read by a student, conveys the same understanding as the original, shorter version. This task involves rephrasing and elaborating the question without altering its fundamental meaning or the response it seeks.\"\n",
        "user_message_1 = \"What kind of cars does Lamborghini make?\"\n",
        "\n",
        "prompt = llama_template.format(your_system_message=your_system_message, user_message_1=user_message_1)\n",
        "\n",
        "texto = pipeline(prompt)\n",
        "\n",
        "print(texto[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "umCYSSRaTlzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "P6-8EkfURWve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "1t6ix6zqO9bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B59-09So98n9"
      },
      "outputs": [],
      "source": [
        "text_1 = \"Automobili Lamborghini, the illustrious Italian manufacturer of luxury sports cars and SUVs, is headquartered in the picturesque Sant'Agata Bolognese. This renowned automotive institution boasts a storied legacy, and its contemporary success is firmly underpinned by a fascinating history that has seen it evolve through ownership changes, economic downturns, and groundbreaking innovations.\\\n",
        "Ferruccio Lamborghini, a prominent Italian industrialist with a passion for automobiles, laid the foundation for this iconic marque in 1963. His vision was audacious - to challenge the supremacy of Ferrari, the undisputed titan of Italian sports cars. Under Ferruccio's guidance, Automobili Ferruccio Lamborghini S.p.A. was established, and it immediately began making waves in the automotive world.\\\n",
        "One of the hallmarks of Lamborghini's early years was its distinctive rear mid-engine, rear-wheel-drive layout. This design philosophy became synonymous with Lamborghini's commitment to creating high-performance vehicles. The company's inaugural models, such as the 350 GT, arrived in the mid-1960s and showcased Lamborghini's dedication to precision engineering and uncompromising quality.\\\n",
        "Lamborghini's ascendancy was nothing short of meteoric during its formative decade. It consistently pushed the boundaries of automotive technology and design. However, the heady days of growth were met with a sudden downturn when the world faced the harsh realities of the 1973 global financial crisis and the subsequent oil embargo. Lamborghini, like many other automakers, grappled with plummeting sales and financial instability.\\\n",
        "Ownership of Lamborghini underwent multiple transitions in the wake of these challenges. The company faced bankruptcy in 1978, marking a turbulent chapter in its history. The ownership baton changed hands several times, with different entities attempting to steer the storied brand to calmer waters.\\\n",
        "In 1987, American automaker Chrysler Corporation took the helm at Lamborghini. The Chrysler era saw Lamborghini continue to produce remarkable vehicles like the Diablo while operating under the umbrella of a global conglomerate. However, it was not a permanent arrangement.\\\n",
        "In 1994, Malaysian investment group Mycom Setdco and Indonesian group V'Power Corporation acquired Lamborghini, signaling another phase of transformation for the company. These new custodians brought fresh perspectives and investment to the brand, fueling its resurgence.\\\n",
        "A significant turning point occurred in 1998 when Mycom Setdco and V'Power sold Lamborghini to the Volkswagen Group, which placed the Italian marque under the stewardship of its Audi division. This move brought newfound stability and resources, ensuring Lamborghini's enduring presence in the luxury sports car arena.\\\n",
        "Over the ensuing years, Lamborghini witnessed remarkable expansions in its product portfolio. The V10-powered Hurac√°n captured the hearts of sports car enthusiasts with its exquisite design and formidable performance. Simultaneously, Lamborghini ventured into the SUV market with the Urus, a groundbreaking vehicle powered by a potent twin-turbo V8 engine. This diversification allowed Lamborghini to cater to a broader range of customers without compromising on its commitment to luxury and performance.\\\n",
        "While these successes were noteworthy, Lamborghini was not immune to the challenges posed by global economic fluctuations. In the late 2000s, during the worldwide financial crisis and the subsequent economic downturn, Lamborghini's sales experienced a significant decline, illustrating the brand's vulnerability to external economic factors.\\\n",
        "Despite these challenges, Lamborghini maintained its relentless pursuit of automotive excellence. The company's flagship model, the V12-powered Aventador, reached the pinnacle of automotive engineering and design before concluding its production run in 2022. However, the story does not end here. Lamborghini is set to introduce the Revuelto, a V12/electric hybrid model, in 2024, exemplifying its commitment to embracing cutting-edge technologies and pushing the boundaries of performance.\\\n",
        "In addition to its road car production, Lamborghini has made notable contributions to other industries. The company manufactures potent V12 engines for offshore powerboat racing, further underscoring its prowess in high-performance engineering.\\\n",
        "Interestingly, Lamborghini's legacy extends beyond the realm of automobiles. Ferruccio Lamborghini founded Lamborghini Trattori in 1948, a separate entity from the automobile manufacturer, which continues to produce tractors to this day.\\\n",
        "Lamborghini's rich history is also intertwined with the world of motorsport. In a stark contrast to his rival Enzo Ferrari, Ferruccio Lamborghini decided early on not to engage in factory-supported racing, considering it too expensive and resource-intensive. Nonetheless, Lamborghini's engineers, many of whom were passionate about racing, embarked on ambitious projects, including the development of the iconic Miura sports coupe, which possessed racing potential while being road-friendly. This project marked a pivotal moment in Lamborghini's history, showcasing its ability to create vehicles that could excel on both the track and the road.Despite Ferruccio's reluctance, Lamborghini did make some forays into motorsport. In the mid-1970s, while under the management of Georges-Henri Rossetti, Lamborghini collaborated with BMW to develop and manufacture 400 cars for BMW, a venture intended to meet Group 4 homologation requirements. However, due to financial instability and delays in development, BMW eventually took control of the project, finishing it without Lamborghini's involvement.\\\n",
        "Lamborghini also briefly supplied engines to Formula One teams from 1989 to 1993. Teams like Larrousse, Lotus, Ligier, Minardi, and Modena utilized Lamborghini power units during this period. Lamborghini's best result in Formula One was achieved when Aguri Suzuki finished third at the 1990 Japanese Grand Prix.\\\n",
        "In addition to Formula One, Lamborghini was involved in other racing series. Notably, racing versions of the Diablo were developed for the Diablo Supertrophy, a single-model racing series that ran from 1996 to 1999. The Murci√©lago R-GT, a production racing car, was created to compete in events like the FIA GT Championship and the American Le Mans Series in 2004, achieving notable results in its racing endeavors.\\\n",
        "Lamborghini's connection with motorsport reflects the brand's commitment to engineering excellence, even though it shied away from factory-backed racing for much of its history.\\\n",
        "Beyond the realms of automotive engineering, Lamborghini has carved a distinct niche in the world of branding. The company licenses its prestigious brand to manufacturers who produce a wide array of Lamborghini-branded consumer goods, including scale models, clothing, accessories, bags, electronics, and even laptop computers. This strategic approach has enabled Lamborghini to extend its brand reach beyond the confines of the automotive industry.\\\n",
        "One fascinating aspect of Lamborghini's identity is its deep connection with the world of bullfighting. In 1962, Ferruccio Lamborghini visited the ranch of Don Eduardo Miura, a renowned breeder of Spanish fighting bulls. Impressed by the majestic Miura animals, Ferruccio decided to adopt a raging bull as the emblem for his burgeoning automaker. This emblem, now iconic, symbolizes Lamborghini's passion for performance, power, and the thrill of the chase.\\\n",
        "Lamborghini's vehicle nomenclature also reflects this bullfighting heritage, with many models bearing the names of famous fighting bulls or bull-related themes. The Miura, named after the Miura bulls, set the precedent, and subsequent models like the Murci√©lago, Gallardo, and Aventador continued this tradition.\\\n",
        "Furthermore, Lamborghini has enthusiastically embraced emerging automotive technologies, responding to environmental concerns and changing consumer preferences. The Sian, introduced as the company's first hybrid model, showcases Lamborghini's commitment to sustainable performance. With its innovative hybrid powertrain, the Sian combines electric propulsion with a naturally aspirated V12 engine to deliver breathtaking performance while minimizing emissions.\\\n",
        "Looking ahead, Lamborghini has ambitious plans to produce an all-electric vehicle, aligning with the broader industry trend towards electrification. While traditionalists may lament the absence of roaring V12 engines, Lamborghini recognizes the importance of evolving with the times, ensuring that future generations of enthusiasts can experience the thrill of a Lamborghini while contributing to a more sustainable future.\\\n",
        "In summary, Automobili Lamborghini stands as a testament to the enduring allure of Italian craftsmanship and automotive excellence. From its audacious beginnings as a challenger to Ferrari, Lamborghini has weathered storms, embraced innovation, and left an indelible mark on the world of sports cars. Its legacy is one of design brilliance, relentless pursuit of power, and a commitment to pushing the boundaries of what's possible in the realm of high-performance automobiles. Whether through its iconic V12-powered supercars, groundbreaking hybrids, or electrifying visions of the future, Lamborghini continues to captivate the hearts of automotive enthusiasts worldwide, cementing its status as a legendary and iconic brand.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEu7mx__03On"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "questions_schema = ResponseSchema(\n",
        "    name=\"questions\",\n",
        "    description=\"Fa√ßa a tradu√ß√£o das seguintes quest√µes do Ingl√™s para o Portugu√™s\",\n",
        ")\n",
        "\n",
        "response_schemas = [questions_schema]\n",
        "\n",
        "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "\n",
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "template = \"\"\"\n",
        "Fa√ßa a tradu√ß√£o do seguinte texto do Ingl√™s para o Portugu√™s.\n",
        "Concentre-se em manter a precis√£o do contexto e do conte√∫do original,\n",
        "evitando adicionar ou alterar palavras que n√£o estejam presentes no texto original.\n",
        "Lembre-se de mostrar a sa√≠da como quest√µes de multipla escolha tradicionais... ou seja, com\n",
        "enunciado em cima, seguido das quatro alternativas, todas em sua linha espec√≠fica.\n",
        "\n",
        "Texto em Ingl√™s: {input}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(template=template)\n",
        "\n",
        "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "translate_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "def format_output(raw_output):\n",
        "    # Separar cada quest√£o e suas alternativas\n",
        "    questions = raw_output.split('\\n\\n')  # Assumindo que cada quest√£o √© separada por duas quebras de linha\n",
        "    formatted_questions = []\n",
        "    for q in questions:\n",
        "        parts = q.split('\\n')\n",
        "        question = parts[0]\n",
        "        alternatives = parts[1:]\n",
        "        formatted_question = question + '\\n' + '\\n'.join(alternatives) +'\\n'\n",
        "        formatted_questions.append(formatted_question)\n",
        "    return '\\n\\n'.join(formatted_questions)\n",
        "\n",
        "def format_questions(_questions):\n",
        "    questions = \"\"\n",
        "\n",
        "    for question in _questions:\n",
        "      questions += format_output(question)\n",
        "\n",
        "    return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCoAP_s0eym5"
      },
      "outputs": [],
      "source": [
        "def limpeza(pages):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size = 1500,\n",
        "      chunk_overlap = 200,\n",
        "      separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "  )\n",
        "  clean_text = text_splitter.split_documents(pages)\n",
        "  return clean_text\n",
        "\n",
        "def web_reader(caminho):\n",
        "    web = WebBaseLoader(caminho)\n",
        "    pages_web = web.load()\n",
        "\n",
        "    pages_web = limpeza(pages_web)\n",
        "\n",
        "    text = \"\"\n",
        "    for page in pages_web:\n",
        "      text += page.page_content\n",
        "\n",
        "    return text\n",
        "\n",
        "def text_reader(caminho):\n",
        "    text = TextLoader(caminho)\n",
        "    pages_text = text.load()\n",
        "\n",
        "    pages_text = limpeza(pages_text)\n",
        "\n",
        "    text = \"\"\n",
        "    for page in pages_text:\n",
        "      text += page.page_content\n",
        "\n",
        "    return text\n",
        "\n",
        "def pdf_reader(caminho):\n",
        "    pdf = PyPDFLoader(caminho)\n",
        "    pages_pdf = pdf.load()\n",
        "\n",
        "    pages_pdf = limpeza(pages_pdf)\n",
        "\n",
        "    text = \"\"\n",
        "    for page in pages_pdf:\n",
        "      text += page.page_content\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U39b0HITfR_G"
      },
      "outputs": [],
      "source": [
        "text_mimetypes = ['txt', 'doc', 'docx', 'rtf', 'md', 'html']\n",
        "audio_mimetypes = ['mp3', 'wav', 'ogg', 'flac', 'aac', 'opus']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFHsnfmmfccz"
      },
      "outputs": [],
      "source": [
        "def load_file(file_path):\n",
        "\n",
        "    mimetype = file_path.split(\".\")[-1]\n",
        "\n",
        "    if mimetype == \"pdf\":\n",
        "\n",
        "      loaded_file = pdf_reader(file_path)\n",
        "\n",
        "    elif mimetype in text_mimetypes:\n",
        "\n",
        "      loaded_file = text_reader(file_path)\n",
        "\n",
        "\n",
        "    return loaded_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBo-HlMCi6HM"
      },
      "outputs": [],
      "source": [
        "text = load_file(\"/content/Writing_Geography.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4aop691-TJ3"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "chain = (summary_template\n",
        "         | summary_model\n",
        "         | RunnableLambda(get_questions)\n",
        "         | RunnableLambda(format_questions)\n",
        "         | translate_chain\n",
        "         )\n",
        "\n",
        "final_questions = chain.invoke({\"text\": text_1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwyD22YX48Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbb6a92-e7f9-4f93-fac9-c458d8f08209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: A Lamborghini evoluiu atrav√©s de mudan√ßas de propriedade, recess√µes econ√¥micas e o qu√™?\n",
            "(a) aumento\n",
            "(b) SUVs\n",
            "(c) inova√ß√µes revolucion√°rias\n",
            "(d) inova√ß√µes revolucion√°rias\n",
            "Resposta correta: (d)\n",
            "\n",
            "Pergunta: A hist√≥ria da Lamborghini viu ela evoluir atrav√©s de mudan√ßas de propriedade, inova√ß√µes revolucion√°rias e o qu√™ mais?\n",
            "(a) recess√µes econ√¥micas\n",
            "(b) aumento\n",
            "(c) grupo de investimento malaio Mycom Setdco\n",
            "(d) t--s\n",
            "Resposta correta: (a)\n",
            "\n",
            "Pergunta: Qual era o nome do grupo de investimento que comprou a Lamborghini em 1994?\n",
            "(a) SUVs\n",
            "(b) aumento\n",
            "(c) grupo de investimento malaio Mycom Setdco\n",
            "(d) t--s\n",
            "Resposta correta: (c)\n",
            "\n",
            "Pergunta: Al√©m do grupo de investimento malaio Mycom Setdco, qual outro grupo se juntou √† Lamborghini em 1994?\n",
            "(a) Afghan\n",
            "(b) Altaic\n",
            "(c) indon√©sio\n",
            "(d) Bangladeshi\n",
            "Resposta correta: (c)\n",
            "\n",
            "Pergunta: O que aconteceu com a Automobili Lamborghini durante sua d√©cada formativa?\n",
            "(a) recess√µes econ√¥micas\n",
            "(b) indon√©sio\n",
            "(c) aumento\n",
            "(d) inova√ß√µes revolucion√°rias\n",
            "Resposta correta: (c)\n",
            "\n",
            "Pergunta: Que tipo de carro a Lamborghini fabrica?\n",
            "(a) Ambul√¢ncia\n",
            "(b) Carro de praia\n",
            "(c) √înibus\n",
            "(d) SUVs\n",
            "Resposta correta: (d)\n",
            "\n",
            "Pergunta: Qual √© o ilustre fabricante italiano de carros esportivos de luxo e SUVs?\n",
            "(a) automobili lamborghini\n",
            "(b) t--s\n",
            "(c) recess√µes econ√¥micas\n",
            "(d) automobili lamborghini\n",
            "Resposta correta: (d)\n",
            "\n",
            "Pergunta: Qual √© a abrevia√ß√£o para Lamborghini?\n",
            "(a) t--s\n",
            "(b) grupo de investimento malaio Mycom Setdco\n",
            "(c) t--s\n",
            "(d) SUVs\n",
            "Resposta correta: (a)\n"
          ]
        }
      ],
      "source": [
        "print(final_questions[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output(raw_output):\n",
        "    # Separar cada quest√£o e suas alternativas\n",
        "    questions = raw_output.split('\\n\\n')  # Assumindo que cada quest√£o √© separada por duas quebras de linha\n",
        "    formatted_questions = []\n",
        "    for q in questions:\n",
        "        parts = q.split('\\n')\n",
        "        question = parts[0]\n",
        "        alternatives = parts[1:]\n",
        "        formatted_question = question + '\\n' + '\\n'.join(alternatives)\n",
        "        formatted_questions.append(formatted_question)\n",
        "    return '\\n\\n'.join(formatted_questions)"
      ],
      "metadata": {
        "id": "LaN9YaTrLrm9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}